{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10729805,"sourceType":"datasetVersion","datasetId":6652233},{"sourceId":10729823,"sourceType":"datasetVersion","datasetId":6652249}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:11.139374Z","iopub.execute_input":"2025-02-17T11:30:11.139805Z","iopub.status.idle":"2025-02-17T11:30:11.164370Z","shell.execute_reply.started":"2025-02-17T11:30:11.139771Z","shell.execute_reply":"2025-02-17T11:30:11.162975Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/im-so-done/Arsenal_Scouting_Data (1).xlsx\n/kaggle/input/defenders-deadlineday/defenders_percentile.csv\n/kaggle/input/defenders-deadlineday/Premier_League_Player_Valuations_2019_2024.csv\n/kaggle/input/im-rly-done-now/defenders_percentile (2).csv\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"#Start with defenders \nvaluations = pd.read_csv(\"...Premier_League_Player_Valuations_2019_2024.csv\")\ndefenders = pd.read_csv(\"...defenders_percentile (2).csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:11.165965Z","iopub.execute_input":"2025-02-17T11:30:11.166341Z","iopub.status.idle":"2025-02-17T11:30:11.227054Z","shell.execute_reply.started":"2025-02-17T11:30:11.166298Z","shell.execute_reply":"2025-02-17T11:30:11.225898Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"#Selecting the market values of the plauers\nplayer_values = valuations[[\"player_name\",\"player_market_value_euro\",\"Season\"]]\nplayer_values = player_values.rename(columns = {\"Season\":\"year\", \"player_name\":\"Player\"})\n\n#Add a year column to allow for joins\nnew_defenders = defenders\nnew_defenders['year'] = new_defenders[\"scouting_period\"].str.extract(r'(\\d{4})').astype(float)\n\n# Convert to integer and drop rows with missing years\nnew_defenders = new_defenders.dropna().astype({'year': 'int'}).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:11.228809Z","iopub.execute_input":"2025-02-17T11:30:11.229133Z","iopub.status.idle":"2025-02-17T11:30:11.260742Z","shell.execute_reply.started":"2025-02-17T11:30:11.229107Z","shell.execute_reply":"2025-02-17T11:30:11.259654Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"#Merge the valuations and the stats\nmerged_df = pd.merge(new_defenders, player_values, on=[\"Player\",\"year\"])\nmerged_df = merged_df._get_numeric_data()\nmerged_df.head(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:11.262785Z","iopub.execute_input":"2025-02-17T11:30:11.263183Z","iopub.status.idle":"2025-02-17T11:30:11.313800Z","shell.execute_reply.started":"2025-02-17T11:30:11.263145Z","shell.execute_reply":"2025-02-17T11:30:11.312579Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"    BasedOnMinutes  Percentile_% of Aerials Won  \\\n0              416                         47.0   \n1             2235                         53.0   \n2             2726                         73.0   \n3             2727                         54.0   \n4             3170                         67.0   \n5              410                         21.0   \n6              723                         66.0   \n7             1435                         27.0   \n8             1714                         24.0   \n9             1780                         54.0   \n10            1793                         15.0   \n11            3060                         51.0   \n12            3070                         21.0   \n13            2055                         62.0   \n14            2943                         27.0   \n15            1434                         97.0   \n16            1985                         80.0   \n17            2594                         49.0   \n18            2668                         56.0   \n19             270                         11.0   \n\n    Percentile_% of Dribblers Tackled  Percentile_Aerials Lost  \\\n0                                72.0                     17.0   \n1                                 9.0                     49.0   \n2                                33.0                     88.0   \n3                                53.0                     52.0   \n4                                68.0                     83.0   \n5                                58.0                     21.0   \n6                                61.0                     80.0   \n7                                99.0                     51.0   \n8                                94.0                     58.0   \n9                                93.0                     51.0   \n10                               93.0                     16.0   \n11                               97.0                     72.0   \n12                               97.0                     74.0   \n13                               36.0                     61.0   \n14                               16.0                     39.0   \n15                               69.0                     90.0   \n16                               37.0                     60.0   \n17                               26.0                     34.0   \n18                               17.0                     33.0   \n19                               17.0                     46.0   \n\n    Percentile_Aerials Won  Percentile_Assists  \\\n0                     82.0                32.0   \n1                     54.0                48.0   \n2                     47.0                60.0   \n3                     54.0                17.0   \n4                     37.0                93.0   \n5                     46.0                36.0   \n6                     36.0                64.0   \n7                     28.0                20.0   \n8                     19.0                35.0   \n9                     51.0                63.0   \n10                    40.0                10.0   \n11                    42.0                74.0   \n12                    13.0                76.0   \n13                    56.0                38.0   \n14                    34.0                43.0   \n15                    88.0                33.0   \n16                    73.0                32.0   \n17                    61.0                36.0   \n18                    69.0                70.0   \n19                    15.0                34.0   \n\n    Percentile_Average Shot Distance  Percentile_Ball Recoveries  \\\n0                               67.0                         3.0   \n1                               19.0                        31.0   \n2                               38.0                        49.0   \n3                               31.0                        70.0   \n4                                4.0                        72.0   \n5                               50.0                        31.0   \n6                               66.0                        39.0   \n7                               75.0                        19.0   \n8                               72.0                        88.0   \n9                               30.0                        43.0   \n10                              91.0                        76.0   \n11                              77.0                        58.0   \n12                              76.0                        53.0   \n13                              46.0                        11.0   \n14                              63.0                         7.0   \n15                              51.0                        62.0   \n16                              54.0                        82.0   \n17                              32.0                        52.0   \n18                              22.0                        82.0   \n19                              41.0                        64.0   \n\n    Percentile_Blocks  Percentile_Carries  ...  Percentile_Touches (Mid 3rd)  \\\n0                 8.0                72.0  ...                          69.0   \n1                15.0                51.0  ...                          51.0   \n2                34.0                89.0  ...                          90.0   \n3                48.0                46.0  ...                          57.0   \n4                16.0                51.0  ...                          62.0   \n5                75.0                43.0  ...                          42.0   \n6                58.0                64.0  ...                          61.0   \n7                78.0                56.0  ...                          38.0   \n8                34.0                40.0  ...                          44.0   \n9                76.0                43.0  ...                          54.0   \n10               62.0                71.0  ...                          64.0   \n11               94.0                81.0  ...                          72.0   \n12               83.0                69.0  ...                          66.0   \n13               62.0                53.0  ...                          30.0   \n14               23.0                 4.0  ...                          15.0   \n15               78.0                80.0  ...                          86.0   \n16               57.0                87.0  ...                          87.0   \n17               34.0                70.0  ...                          74.0   \n18               77.0                67.0  ...                          69.0   \n19               27.0                61.0  ...                          39.0   \n\n    Percentile_Yellow Cards  Percentile_npxG + xAG  Percentile_npxG/Shot  \\\n0                      46.0                   26.0                  78.0   \n1                      77.0                   77.0                  16.0   \n2                      66.0                   62.0                  49.0   \n3                      38.0                   67.0                  70.0   \n4                      77.0                   87.0                  38.0   \n5                      83.0                   61.0                  63.0   \n6                      35.0                   11.0                  51.0   \n7                      75.0                   70.0                  89.0   \n8                      94.0                   44.0                  77.0   \n9                      49.0                   20.0                  22.0   \n10                     64.0                   11.0                  65.0   \n11                     76.0                   37.0                  94.0   \n12                     35.0                   43.0                  85.0   \n13                     16.0                   28.0                  96.0   \n14                      8.0                   16.0                  78.0   \n15                     17.0                   35.0                  80.0   \n16                     72.0                   60.0                  56.0   \n17                     52.0                   60.0                  43.0   \n18                     64.0                   64.0                  36.0   \n19                     73.0                   69.0                  32.0   \n\n    Percentile_npxG: Non-Penalty xG  Percentile_xA: Expected Assists  \\\n0                              36.0                             47.0   \n1                              14.0                             79.0   \n2                              56.0                             63.0   \n3                              74.0                             50.0   \n4                              38.0                             87.0   \n5                              67.0                             66.0   \n6                              31.0                             28.0   \n7                              83.0                             48.0   \n8                              66.0                             49.0   \n9                               6.0                             49.0   \n10                             18.0                             19.0   \n11                             32.0                             42.0   \n12                             38.0                             63.0   \n13                             56.0                             10.0   \n14                             20.0                             33.0   \n15                             59.0                             45.0   \n16                             83.0                             33.0   \n17                             81.0                             55.0   \n18                             48.0                             72.0   \n19                             54.0                             95.0   \n\n    Percentile_xAG: Exp. Assisted Goals  Percentile_xG: Expected Goals  year  \\\n0                                  31.0                           35.0  2023   \n1                                  84.0                           14.0  2022   \n2                                  64.0                           56.0  2021   \n3                                  61.0                           74.0  2019   \n4                                  91.0                           38.0  2020   \n5                                  68.0                           67.0  2022   \n6                                  18.0                           30.0  2020   \n7                                  51.0                           83.0  2022   \n8                                  40.0                           66.0  2024   \n9                                  46.0                            6.0  2023   \n10                                 15.0                           18.0  2021   \n11                                 51.0                           32.0  2020   \n12                                 53.0                           38.0  2019   \n13                                 26.0                           56.0  2019   \n14                                 31.0                           20.0  2022   \n15                                  6.0                           59.0  2021   \n16                                 24.0                           83.0  2022   \n17                                 31.0                           80.0  2020   \n18                                 83.0                           48.0  2019   \n19                                 86.0                           50.0  2021   \n\n    player_market_value_euro  \n0                   900000.0  \n1                  1200000.0  \n2                  3000000.0  \n3                  6500000.0  \n4                  5000000.0  \n5                 25000000.0  \n6                 40000000.0  \n7                 25000000.0  \n8                 22000000.0  \n9                 20000000.0  \n10                25000000.0  \n11                40000000.0  \n12                32000000.0  \n13                 7000000.0  \n14                 1200000.0  \n15                17000000.0  \n16                25000000.0  \n17                18000000.0  \n18                12000000.0  \n19                65000000.0  \n\n[20 rows x 120 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BasedOnMinutes</th>\n      <th>Percentile_% of Aerials Won</th>\n      <th>Percentile_% of Dribblers Tackled</th>\n      <th>Percentile_Aerials Lost</th>\n      <th>Percentile_Aerials Won</th>\n      <th>Percentile_Assists</th>\n      <th>Percentile_Average Shot Distance</th>\n      <th>Percentile_Ball Recoveries</th>\n      <th>Percentile_Blocks</th>\n      <th>Percentile_Carries</th>\n      <th>...</th>\n      <th>Percentile_Touches (Mid 3rd)</th>\n      <th>Percentile_Yellow Cards</th>\n      <th>Percentile_npxG + xAG</th>\n      <th>Percentile_npxG/Shot</th>\n      <th>Percentile_npxG: Non-Penalty xG</th>\n      <th>Percentile_xA: Expected Assists</th>\n      <th>Percentile_xAG: Exp. Assisted Goals</th>\n      <th>Percentile_xG: Expected Goals</th>\n      <th>year</th>\n      <th>player_market_value_euro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>416</td>\n      <td>47.0</td>\n      <td>72.0</td>\n      <td>17.0</td>\n      <td>82.0</td>\n      <td>32.0</td>\n      <td>67.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>72.0</td>\n      <td>...</td>\n      <td>69.0</td>\n      <td>46.0</td>\n      <td>26.0</td>\n      <td>78.0</td>\n      <td>36.0</td>\n      <td>47.0</td>\n      <td>31.0</td>\n      <td>35.0</td>\n      <td>2023</td>\n      <td>900000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2235</td>\n      <td>53.0</td>\n      <td>9.0</td>\n      <td>49.0</td>\n      <td>54.0</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>31.0</td>\n      <td>15.0</td>\n      <td>51.0</td>\n      <td>...</td>\n      <td>51.0</td>\n      <td>77.0</td>\n      <td>77.0</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>79.0</td>\n      <td>84.0</td>\n      <td>14.0</td>\n      <td>2022</td>\n      <td>1200000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2726</td>\n      <td>73.0</td>\n      <td>33.0</td>\n      <td>88.0</td>\n      <td>47.0</td>\n      <td>60.0</td>\n      <td>38.0</td>\n      <td>49.0</td>\n      <td>34.0</td>\n      <td>89.0</td>\n      <td>...</td>\n      <td>90.0</td>\n      <td>66.0</td>\n      <td>62.0</td>\n      <td>49.0</td>\n      <td>56.0</td>\n      <td>63.0</td>\n      <td>64.0</td>\n      <td>56.0</td>\n      <td>2021</td>\n      <td>3000000.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2727</td>\n      <td>54.0</td>\n      <td>53.0</td>\n      <td>52.0</td>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>31.0</td>\n      <td>70.0</td>\n      <td>48.0</td>\n      <td>46.0</td>\n      <td>...</td>\n      <td>57.0</td>\n      <td>38.0</td>\n      <td>67.0</td>\n      <td>70.0</td>\n      <td>74.0</td>\n      <td>50.0</td>\n      <td>61.0</td>\n      <td>74.0</td>\n      <td>2019</td>\n      <td>6500000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3170</td>\n      <td>67.0</td>\n      <td>68.0</td>\n      <td>83.0</td>\n      <td>37.0</td>\n      <td>93.0</td>\n      <td>4.0</td>\n      <td>72.0</td>\n      <td>16.0</td>\n      <td>51.0</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>77.0</td>\n      <td>87.0</td>\n      <td>38.0</td>\n      <td>38.0</td>\n      <td>87.0</td>\n      <td>91.0</td>\n      <td>38.0</td>\n      <td>2020</td>\n      <td>5000000.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>410</td>\n      <td>21.0</td>\n      <td>58.0</td>\n      <td>21.0</td>\n      <td>46.0</td>\n      <td>36.0</td>\n      <td>50.0</td>\n      <td>31.0</td>\n      <td>75.0</td>\n      <td>43.0</td>\n      <td>...</td>\n      <td>42.0</td>\n      <td>83.0</td>\n      <td>61.0</td>\n      <td>63.0</td>\n      <td>67.0</td>\n      <td>66.0</td>\n      <td>68.0</td>\n      <td>67.0</td>\n      <td>2022</td>\n      <td>25000000.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>723</td>\n      <td>66.0</td>\n      <td>61.0</td>\n      <td>80.0</td>\n      <td>36.0</td>\n      <td>64.0</td>\n      <td>66.0</td>\n      <td>39.0</td>\n      <td>58.0</td>\n      <td>64.0</td>\n      <td>...</td>\n      <td>61.0</td>\n      <td>35.0</td>\n      <td>11.0</td>\n      <td>51.0</td>\n      <td>31.0</td>\n      <td>28.0</td>\n      <td>18.0</td>\n      <td>30.0</td>\n      <td>2020</td>\n      <td>40000000.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1435</td>\n      <td>27.0</td>\n      <td>99.0</td>\n      <td>51.0</td>\n      <td>28.0</td>\n      <td>20.0</td>\n      <td>75.0</td>\n      <td>19.0</td>\n      <td>78.0</td>\n      <td>56.0</td>\n      <td>...</td>\n      <td>38.0</td>\n      <td>75.0</td>\n      <td>70.0</td>\n      <td>89.0</td>\n      <td>83.0</td>\n      <td>48.0</td>\n      <td>51.0</td>\n      <td>83.0</td>\n      <td>2022</td>\n      <td>25000000.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1714</td>\n      <td>24.0</td>\n      <td>94.0</td>\n      <td>58.0</td>\n      <td>19.0</td>\n      <td>35.0</td>\n      <td>72.0</td>\n      <td>88.0</td>\n      <td>34.0</td>\n      <td>40.0</td>\n      <td>...</td>\n      <td>44.0</td>\n      <td>94.0</td>\n      <td>44.0</td>\n      <td>77.0</td>\n      <td>66.0</td>\n      <td>49.0</td>\n      <td>40.0</td>\n      <td>66.0</td>\n      <td>2024</td>\n      <td>22000000.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1780</td>\n      <td>54.0</td>\n      <td>93.0</td>\n      <td>51.0</td>\n      <td>51.0</td>\n      <td>63.0</td>\n      <td>30.0</td>\n      <td>43.0</td>\n      <td>76.0</td>\n      <td>43.0</td>\n      <td>...</td>\n      <td>54.0</td>\n      <td>49.0</td>\n      <td>20.0</td>\n      <td>22.0</td>\n      <td>6.0</td>\n      <td>49.0</td>\n      <td>46.0</td>\n      <td>6.0</td>\n      <td>2023</td>\n      <td>20000000.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1793</td>\n      <td>15.0</td>\n      <td>93.0</td>\n      <td>16.0</td>\n      <td>40.0</td>\n      <td>10.0</td>\n      <td>91.0</td>\n      <td>76.0</td>\n      <td>62.0</td>\n      <td>71.0</td>\n      <td>...</td>\n      <td>64.0</td>\n      <td>64.0</td>\n      <td>11.0</td>\n      <td>65.0</td>\n      <td>18.0</td>\n      <td>19.0</td>\n      <td>15.0</td>\n      <td>18.0</td>\n      <td>2021</td>\n      <td>25000000.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3060</td>\n      <td>51.0</td>\n      <td>97.0</td>\n      <td>72.0</td>\n      <td>42.0</td>\n      <td>74.0</td>\n      <td>77.0</td>\n      <td>58.0</td>\n      <td>94.0</td>\n      <td>81.0</td>\n      <td>...</td>\n      <td>72.0</td>\n      <td>76.0</td>\n      <td>37.0</td>\n      <td>94.0</td>\n      <td>32.0</td>\n      <td>42.0</td>\n      <td>51.0</td>\n      <td>32.0</td>\n      <td>2020</td>\n      <td>40000000.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3070</td>\n      <td>21.0</td>\n      <td>97.0</td>\n      <td>74.0</td>\n      <td>13.0</td>\n      <td>76.0</td>\n      <td>76.0</td>\n      <td>53.0</td>\n      <td>83.0</td>\n      <td>69.0</td>\n      <td>...</td>\n      <td>66.0</td>\n      <td>35.0</td>\n      <td>43.0</td>\n      <td>85.0</td>\n      <td>38.0</td>\n      <td>63.0</td>\n      <td>53.0</td>\n      <td>38.0</td>\n      <td>2019</td>\n      <td>32000000.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2055</td>\n      <td>62.0</td>\n      <td>36.0</td>\n      <td>61.0</td>\n      <td>56.0</td>\n      <td>38.0</td>\n      <td>46.0</td>\n      <td>11.0</td>\n      <td>62.0</td>\n      <td>53.0</td>\n      <td>...</td>\n      <td>30.0</td>\n      <td>16.0</td>\n      <td>28.0</td>\n      <td>96.0</td>\n      <td>56.0</td>\n      <td>10.0</td>\n      <td>26.0</td>\n      <td>56.0</td>\n      <td>2019</td>\n      <td>7000000.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2943</td>\n      <td>27.0</td>\n      <td>16.0</td>\n      <td>39.0</td>\n      <td>34.0</td>\n      <td>43.0</td>\n      <td>63.0</td>\n      <td>7.0</td>\n      <td>23.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>8.0</td>\n      <td>16.0</td>\n      <td>78.0</td>\n      <td>20.0</td>\n      <td>33.0</td>\n      <td>31.0</td>\n      <td>20.0</td>\n      <td>2022</td>\n      <td>1200000.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1434</td>\n      <td>97.0</td>\n      <td>69.0</td>\n      <td>90.0</td>\n      <td>88.0</td>\n      <td>33.0</td>\n      <td>51.0</td>\n      <td>62.0</td>\n      <td>78.0</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>86.0</td>\n      <td>17.0</td>\n      <td>35.0</td>\n      <td>80.0</td>\n      <td>59.0</td>\n      <td>45.0</td>\n      <td>6.0</td>\n      <td>59.0</td>\n      <td>2021</td>\n      <td>17000000.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1985</td>\n      <td>80.0</td>\n      <td>37.0</td>\n      <td>60.0</td>\n      <td>73.0</td>\n      <td>32.0</td>\n      <td>54.0</td>\n      <td>82.0</td>\n      <td>57.0</td>\n      <td>87.0</td>\n      <td>...</td>\n      <td>87.0</td>\n      <td>72.0</td>\n      <td>60.0</td>\n      <td>56.0</td>\n      <td>83.0</td>\n      <td>33.0</td>\n      <td>24.0</td>\n      <td>83.0</td>\n      <td>2022</td>\n      <td>25000000.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2594</td>\n      <td>49.0</td>\n      <td>26.0</td>\n      <td>34.0</td>\n      <td>61.0</td>\n      <td>36.0</td>\n      <td>32.0</td>\n      <td>52.0</td>\n      <td>34.0</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>74.0</td>\n      <td>52.0</td>\n      <td>60.0</td>\n      <td>43.0</td>\n      <td>81.0</td>\n      <td>55.0</td>\n      <td>31.0</td>\n      <td>80.0</td>\n      <td>2020</td>\n      <td>18000000.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2668</td>\n      <td>56.0</td>\n      <td>17.0</td>\n      <td>33.0</td>\n      <td>69.0</td>\n      <td>70.0</td>\n      <td>22.0</td>\n      <td>82.0</td>\n      <td>77.0</td>\n      <td>67.0</td>\n      <td>...</td>\n      <td>69.0</td>\n      <td>64.0</td>\n      <td>64.0</td>\n      <td>36.0</td>\n      <td>48.0</td>\n      <td>72.0</td>\n      <td>83.0</td>\n      <td>48.0</td>\n      <td>2019</td>\n      <td>12000000.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>270</td>\n      <td>11.0</td>\n      <td>17.0</td>\n      <td>46.0</td>\n      <td>15.0</td>\n      <td>34.0</td>\n      <td>41.0</td>\n      <td>64.0</td>\n      <td>27.0</td>\n      <td>61.0</td>\n      <td>...</td>\n      <td>39.0</td>\n      <td>73.0</td>\n      <td>69.0</td>\n      <td>32.0</td>\n      <td>54.0</td>\n      <td>95.0</td>\n      <td>86.0</td>\n      <td>50.0</td>\n      <td>2021</td>\n      <td>65000000.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 120 columns</p>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"#Prepare train, test and validation data\n\nY = merged_df['player_market_value_euro']\nX = merged_df.drop('player_market_value_euro', axis=1)\n\n#Split training, validaton and test data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain_x, val_x, train_y, val_y = train_test_split(X, Y, random_state = 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:11.314584Z","iopub.execute_input":"2025-02-17T11:30:11.314943Z","iopub.status.idle":"2025-02-17T11:30:11.323767Z","shell.execute_reply.started":"2025-02-17T11:30:11.314877Z","shell.execute_reply":"2025-02-17T11:30:11.322789Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"#import XGBoost\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\n\nmy_model = xgb.XGBRegressor(n_estimators = 500)\n\nmy_model.fit(train_x, train_y,\n           early_stopping_rounds=50,\n           eval_set=[(val_x, val_y)],\n           verbose=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:11.325044Z","iopub.execute_input":"2025-02-17T11:30:11.325383Z","iopub.status.idle":"2025-02-17T11:30:11.969879Z","shell.execute_reply.started":"2025-02-17T11:30:11.325321Z","shell.execute_reply":"2025-02-17T11:30:11.968938Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=500, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)","text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=500, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=500, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"#Get predictions \npredictions = my_model.predict(val_x)\nrmse = mean_squared_error(val_y, predictions, squared=False)\nprint(rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:11.970756Z","iopub.execute_input":"2025-02-17T11:30:11.971034Z","iopub.status.idle":"2025-02-17T11:30:11.993112Z","shell.execute_reply.started":"2025-02-17T11:30:11.971013Z","shell.execute_reply":"2025-02-17T11:30:11.991944Z"}},"outputs":[{"name":"stdout","text":"16428169.761377301\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"#Importing optuna to find ideal hyperparameters for the model \nimport optuna\ndef objective(trial):\n    params = {\n        \"objective\": \"reg:squarederror\",\n        \"n_estimators\": 1000,\n        \"verbosity\": 0,\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n    }\n    \n    op_model = xgb.XGBRegressor(**params)\n    op_model.fit(train_x, train_y, verbose=False)\n    predictions = op_model.predict(val_x)\n    rmse = mean_squared_error(val_y, predictions, squared=False)\n    return rmse\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:11.994309Z","iopub.execute_input":"2025-02-17T11:30:11.994730Z","iopub.status.idle":"2025-02-17T11:30:12.006477Z","shell.execute_reply.started":"2025-02-17T11:30:11.994697Z","shell.execute_reply":"2025-02-17T11:30:12.005472Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"#Running the optuna trial\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:12.008890Z","iopub.execute_input":"2025-02-17T11:30:12.009246Z","iopub.status.idle":"2025-02-17T11:30:22.390165Z","shell.execute_reply.started":"2025-02-17T11:30:12.009191Z","shell.execute_reply":"2025-02-17T11:30:22.388599Z"}},"outputs":[{"name":"stderr","text":"[I 2025-02-17 11:30:12,023] A new study created in memory with name: no-name-302a9242-7059-47a5-a5e0-347c049318b9\n[I 2025-02-17 11:30:13,039] Trial 0 finished with value: 17011544.28595318 and parameters: {'learning_rate': 0.061644538780808354, 'max_depth': 8, 'subsample': 0.17014174188517006, 'colsample_bytree': 0.46772877256337897, 'min_child_weight': 15}. Best is trial 0 with value: 17011544.28595318.\n[I 2025-02-17 11:30:16,273] Trial 1 finished with value: 16101723.518422972 and parameters: {'learning_rate': 0.0068916307089942844, 'max_depth': 6, 'subsample': 0.7763193484623727, 'colsample_bytree': 0.3714881391182667, 'min_child_weight': 18}. Best is trial 1 with value: 16101723.518422972.\n[I 2025-02-17 11:30:17,168] Trial 2 finished with value: 16885803.11189803 and parameters: {'learning_rate': 0.034528807822827794, 'max_depth': 2, 'subsample': 0.9796201740795304, 'colsample_bytree': 0.4224767571710788, 'min_child_weight': 18}. Best is trial 1 with value: 16101723.518422972.\n[I 2025-02-17 11:30:18,510] Trial 3 finished with value: 16519408.857969413 and parameters: {'learning_rate': 0.00979031948752667, 'max_depth': 10, 'subsample': 0.25333091022498444, 'colsample_bytree': 0.6570166335800024, 'min_child_weight': 14}. Best is trial 1 with value: 16101723.518422972.\n[I 2025-02-17 11:30:19,605] Trial 4 finished with value: 17011149.79922316 and parameters: {'learning_rate': 0.004246555969280591, 'max_depth': 3, 'subsample': 0.2356532637277624, 'colsample_bytree': 0.7052662151130258, 'min_child_weight': 16}. Best is trial 1 with value: 16101723.518422972.\n[I 2025-02-17 11:30:21,862] Trial 5 finished with value: 16355444.425202044 and parameters: {'learning_rate': 0.040060711706305194, 'max_depth': 7, 'subsample': 0.26837470652360673, 'colsample_bytree': 0.40358819164143506, 'min_child_weight': 3}. Best is trial 1 with value: 16101723.518422972.\n[W 2025-02-17 11:30:22,356] Trial 6 failed with parameters: {'learning_rate': 0.015868129416246473, 'max_depth': 8, 'subsample': 0.4932259980091307, 'colsample_bytree': 0.40753703445051526, 'min_child_weight': 7} because of the following error: KeyboardInterrupt().\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n  File \"<ipython-input-49-29910ff37a69>\", line 16, in objective\n    op_model.fit(train_x, train_y, verbose=False)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1090, in fit\n    self._Booster = train(\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n    bst.update(dtrain, i, obj)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2047, in update\n    self._assign_dmatrix_features(dtrain)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2930, in _assign_dmatrix_features\n    if self.feature_names is None:\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 1997, in feature_names\n    return self._get_feature_info(\"feature_name\")\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 1954, in _get_feature_info\n    feature_info = from_cstr_to_pystr(sarr, length)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 109, in from_cstr_to_pystr\n    res.append(str(cast(bytes, data[i]).decode(\"ascii\")))\nKeyboardInterrupt\n[W 2025-02-17 11:30:22,360] Trial 6 failed with value None.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-673368801853>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Running the optuna trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-49-29910ff37a69>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mop_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             )\n\u001b[0;32m-> 1090\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1091\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2045\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid training matrix: {type(dtrain).__name__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_dmatrix_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_assign_dmatrix_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2928\u001b[0m         \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2930\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mfeature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \"\"\"\n\u001b[0;32m-> 1997\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_feature_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_get_feature_info\u001b[0;34m(self, field)\u001b[0m\n\u001b[1;32m   1952\u001b[0m             )\n\u001b[1;32m   1953\u001b[0m         )\n\u001b[0;32m-> 1954\u001b[0;31m         \u001b[0mfeature_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_cstr_to_pystr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_info\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfeature_info\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mfrom_cstr_to_pystr\u001b[0;34m(data, length)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ascii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":50},{"cell_type":"code","source":"#Train best model\nbest_model = xgb.XGBRegressor(n_estimators = 1000, verbosity = 0, learning_rate = 0.01116452825266398, max_depth = 5, subsample = 0.6588063599139974,\n            colsample_bytree = 0.9166236505068187, min_child_weight = 13)\nbest_model.fit(train_x, train_y, early_stopping_rounds = 50, eval_set=[(val_x, val_y)],verbose = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:28.274756Z","iopub.execute_input":"2025-02-17T11:30:28.275095Z","iopub.status.idle":"2025-02-17T11:30:29.964977Z","shell.execute_reply.started":"2025-02-17T11:30:28.275067Z","shell.execute_reply":"2025-02-17T11:30:29.963956Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.9166236505068187, device=None,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.01116452825266398, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=5, max_leaves=None,\n             min_child_weight=13, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=1000, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)","text/html":"<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.9166236505068187, device=None,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.01116452825266398, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=5, max_leaves=None,\n             min_child_weight=13, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=1000, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.9166236505068187, device=None,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.01116452825266398, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=5, max_leaves=None,\n             min_child_weight=13, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=1000, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"#Get best predictions\npredictions = best_model.predict(val_x)\nrmse = mean_squared_error(val_y, predictions, squared=False)\nprint(rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:30:46.174788Z","iopub.execute_input":"2025-02-17T11:30:46.175200Z","iopub.status.idle":"2025-02-17T11:30:46.211027Z","shell.execute_reply.started":"2025-02-17T11:30:46.175160Z","shell.execute_reply":"2025-02-17T11:30:46.209687Z"}},"outputs":[{"name":"stdout","text":"15993004.158200238\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}